{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b606a8",
   "metadata": {},
   "source": [
    "# PySpark Interview Q&A with Practical Examples\n",
    "\n",
    "This notebook contains 56 PySpark interview questions with concise, interview-style answers and example code snippets.\n",
    "All examples use the following preloaded DataFrames from your uploaded notebook:\n",
    "- `emp_df` (Employees)\n",
    "- `dept_df` (Departments)\n",
    "- `orders_df` (Orders)\n",
    "- `sales_df` (Sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c164cf3",
   "metadata": {},
   "source": [
    "### 1. What is PySpark?\n",
    "**Answer:** PySpark is the Python API for Apache Spark, enabling distributed data processing using Spark’s RDD/DataFrame/Dataset abstractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a948510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"InterviewDemo\").getOrCreate()\n",
    "emp_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d9ebb3",
   "metadata": {},
   "source": [
    "### 2. Explain RDD.\n",
    "**Answer:** RDD (Resilient Distributed Dataset) is Spark’s low-level immutable distributed collection. It supports transformations and actions and provides fault tolerance via lineage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bc186",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = orders_df.rdd\n",
    "amounts = rdd.map(lambda r: r['amount']).collect()\n",
    "print(amounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5a006",
   "metadata": {},
   "source": [
    "### 3. What is a DataFrame?\n",
    "**Answer:** A DataFrame is a distributed dataset organized into named columns with a schema. It provides optimizations via the Catalyst optimizer and supports SQL-like operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910448eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.printSchema()\n",
    "orders_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7b041",
   "metadata": {},
   "source": [
    "### 4. Difference between RDD and DataFrame.\n",
    "**Answer:** DataFrames have schema and optimization support; RDDs are low-level and untyped. DataFrames are preferred for structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DF rows:\", orders_df.count())\n",
    "print(\"RDD rows:\", orders_df.rdd.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d9daf",
   "metadata": {},
   "source": [
    "### 5. What is SparkSession?\n",
    "**Answer:** SparkSession is the unified entry point to Spark; it replaces older contexts and gives access to all Spark features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0faa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "print(\"Spark version:\", spark.version)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
